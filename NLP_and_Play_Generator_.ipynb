{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GirishNaik711/NLP_Play_Generator/blob/main/NLP_and_Play_Generator_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF5wu-AW1-P2"
      },
      "source": [
        "#Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p45fnbaq1-rP"
      },
      "outputs": [],
      "source": [
        "vocab = {}\n",
        "word_encoding = 1\n",
        "\n",
        "def bag_of_words(text):\n",
        "  global word_encoding\n",
        "\n",
        "  words = text.lower().split(\" \")\n",
        "  bag = {}\n",
        "\n",
        "  for word in words:\n",
        "    if word in vocab:\n",
        "      encoding = vocab[word]\n",
        "    else:\n",
        "      vocab[word] = word_encoding\n",
        "      encoding = word_encoding\n",
        "      word_encoding += 1\n",
        "\n",
        "    if encoding in bag:\n",
        "      bag[encoding] += 1\n",
        "    else:\n",
        "      bag[encoding] = 1\n",
        "\n",
        "  return bag\n",
        "\n",
        "text = \"Hi Hi how are you sir Hi ok fine thank you\"\n",
        "bag = bag_of_words(text)\n",
        "\n",
        "print(bag)\n",
        "print(vocab)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbPgAqJ814gw"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "#from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS6LOyfYMxd-"
      },
      "outputs": [],
      "source": [
        "vocab_size = 88584\n",
        "Maxlen = 250\n",
        "batch_size = 64\n",
        "\n",
        "(train_data, train_label), (test_data, test_label) = imdb.load_data(num_words = vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88cLPVYXPwqy"
      },
      "outputs": [],
      "source": [
        "train_data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_45b8zLvNaW9"
      },
      "outputs": [],
      "source": [
        "train_data = pad_sequences(train_data, Maxlen)\n",
        "test_data = pad_sequences(test_data, Maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND6vX6WiNYbx",
        "outputId": "61ac5f85-1e75-4180-b606-d3999b93d738"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     1,   194,\n",
              "        1153,   194,  8255,    78,   228,     5,     6,  1463,  4369,\n",
              "        5012,   134,    26,     4,   715,     8,   118,  1634,    14,\n",
              "         394,    20,    13,   119,   954,   189,   102,     5,   207,\n",
              "         110,  3103,    21,    14,    69,   188,     8,    30,    23,\n",
              "           7,     4,   249,   126,    93,     4,   114,     9,  2300,\n",
              "        1523,     5,   647,     4,   116,     9,    35,  8163,     4,\n",
              "         229,     9,   340,  1322,     4,   118,     9,     4,   130,\n",
              "        4901,    19,     4,  1002,     5,    89,    29,   952,    46,\n",
              "          37,     4,   455,     9,    45,    43,    38,  1543,  1905,\n",
              "         398,     4,  1649,    26,  6853,     5,   163,    11,  3215,\n",
              "       10156,     4,  1153,     9,   194,   775,     7,  8255, 11596,\n",
              "         349,  2637,   148,   605, 15358,  8003,    15,   123,   125,\n",
              "          68, 23141,  6853,    15,   349,   165,  4362,    98,     5,\n",
              "           4,   228,     9,    43, 36893,  1157,    15,   299,   120,\n",
              "           5,   120,   174,    11,   220,   175,   136,    50,     9,\n",
              "        4373,   228,  8255,     5, 25249,   656,   245,  2350,     5,\n",
              "           4,  9837,   131,   152,   491,    18, 46151,    32,  7464,\n",
              "        1212,    14,     9,     6,   371,    78,    22,   625,    64,\n",
              "        1382,     9,     8,   168,   145,    23,     4,  1690,    15,\n",
              "          16,     4,  1355,     5,    28,     6,    52,   154,   462,\n",
              "          33,    89,    78,   285,    16,   145,    95], dtype=int32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQVUL3KQPufp"
      },
      "outputs": [],
      "source": [
        "from keras.layers.serialization import activation\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 32),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t4hxjqVQn48"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop', loss = 'binary_crossentropy', metrics = ['acc'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnv4s2TCRDXp",
        "outputId": "44fc070d-d8cc-45b2-e6e4-16c14b272982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 74s 100ms/step - loss: 0.4519 - acc: 0.7835 - val_loss: 0.3104 - val_acc: 0.8728\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 27s 43ms/step - loss: 0.2566 - acc: 0.9017 - val_loss: 0.2982 - val_acc: 0.8756\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.1963 - acc: 0.9295 - val_loss: 0.3308 - val_acc: 0.8826\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 0.1578 - acc: 0.9436 - val_loss: 0.3370 - val_acc: 0.8844\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 11s 18ms/step - loss: 0.1285 - acc: 0.9566 - val_loss: 0.3334 - val_acc: 0.8738\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.1063 - acc: 0.9646 - val_loss: 0.3617 - val_acc: 0.8626\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 0.0899 - acc: 0.9712 - val_loss: 0.3746 - val_acc: 0.8704\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.0731 - acc: 0.9773 - val_loss: 0.3812 - val_acc: 0.8724\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.0591 - acc: 0.9807 - val_loss: 0.4395 - val_acc: 0.8732\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.0484 - acc: 0.9851 - val_loss: 0.4480 - val_acc: 0.8758\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_data, train_label,epochs = 10, validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xgRfyq5hRRq4",
        "outputId": "095544dc-4a43-42b9-9dc9-2fb6a464377e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 4s 5ms/step - loss: 0.4915 - acc: 0.8631\n",
            "[0.49154961109161377, 0.8630800247192383]\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(test_data, test_label)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7gtTVKA2RgOk",
        "outputId": "abb711a2-fc9c-4563-8321-240df09c7af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0  10 444   1  17   9  13   3  84  28]\n"
          ]
        }
      ],
      "source": [
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def encode(text):\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return pad_sequences([tokens], Maxlen)[0]\n",
        "\n",
        "text = \"I loved the movie it was a great one\"\n",
        "encoded = encode(text)\n",
        "print(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GXoWMAk1SusC",
        "outputId": "4a2c944b-2eec-4012-c9d4-0b46f709bfc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " i loved the movie it was a great one\n"
          ]
        }
      ],
      "source": [
        "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
        "\n",
        "def decode(integers):\n",
        "  pad = 0\n",
        "  text = \" \"\n",
        "  for num in integers:\n",
        "    if num != pad:\n",
        "      text += reverse_word_index[num] + \" \"\n",
        "\n",
        "  return text[:-1]\n",
        "\n",
        "print(decode(encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M__rp0MWTzbm",
        "outputId": "f4db3105-677f-40d9-bf90-bdcfb5440ef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 582ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.2569266]], dtype=float32)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def predict(text):\n",
        "  encoded_text = encode(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0] = encoded_text\n",
        "  prediction =  model.predict(pred)\n",
        "  return prediction\n",
        "\n",
        "review = \"it was a bad movie i would never want to watch anything like this\"\n",
        "predict(review)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "87z6mrbUZI3_"
      },
      "outputs": [],
      "source": [
        "model.save('sentiment_analysis.h5', )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LnkZrLoyN9LF"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cHm-HwjRN9H8",
        "outputId": "6427e3d2-e129-4bb3-e65d-1a6e573609f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5r-Tfr8nN9Es"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "#path_to_file = list(files.upload()keys())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EdQ3uNwqN9BC",
        "outputId": "bbfdea7c-dc34-4f17-f8e9-0c34ff75dc01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of text file 1115394\n"
          ]
        }
      ],
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding = 'utf-8')\n",
        "print(f\"length of text file {len(text)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-B-N6EATN87c",
        "outputId": "347fde9c-12d3-4145-be26-12c46b5918f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p6ZaW1hpN84I"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(set(text))\n",
        "\n",
        "char2idx = {u:i for i,u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "   return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int = text_to_int(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c97bqHA3VH21",
        "outputId": "18110ea3-9c01-4c30-f455-8cee765eec42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: First Citizen\n",
            "Encoded Text: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Text: {text[:13]}\")\n",
        "print(f\"Encoded Text: {text_to_int(text[:13])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lh706WScN81P"
      },
      "outputs": [],
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  return ''.join(idx2char[ints])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MhMpzrOoN8yi",
        "outputId": "64bebbb5-c67e-47b4-950d-c0f38a842abf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(int_to_text(text_as_int[:15]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "magJ3im3N8vT"
      },
      "outputs": [],
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text) // (seq_length+1)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n6Ma5klLWqmy",
        "outputId": "54a8be07-7f85-4732-d513-f14f5393c7e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1115394\n",
            "11043\n"
          ]
        }
      ],
      "source": [
        "print(len(char_dataset))\n",
        "print(examples_per_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sYEz97EVXGx6"
      },
      "outputs": [],
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8UMCTlv7Z9p5",
        "outputId": "a3bc3098-aaf3-42b7-de73-7066d15d8d0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11043\n"
          ]
        }
      ],
      "source": [
        "print(len(sequences))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0zzvANvGaAQy"
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text  = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "orjzrymMbP3d",
        "outputId": "6b83ade8-17c3-4ad2-858a-f9cc004e0c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11043\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2BDi7MGfcCPr",
        "outputId": "ed02760c-759a-49b2-9256-48a1099c629e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Example\n",
            "\n",
            "Input\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "100\n",
            "\n",
            "Output\n",
            "\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n"
          ]
        }
      ],
      "source": [
        "for x,y in dataset.take(1):\n",
        "  print(\"\\n\\nExample\\n\")\n",
        "  print(\"Input\")\n",
        "  print(int_to_text(x))\n",
        "  print(len(x))\n",
        "  print(\"\\nOutput\\n\")\n",
        "  print(int_to_text(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ylDSv2__cbKf"
      },
      "outputs": [],
      "source": [
        "Batch_Size = 64\n",
        "Vocab_Size = len(vocab)\n",
        "Embedding_Dim = 256\n",
        "RNN_Units = 1024\n",
        "\n",
        "Buffer_Size = 1000\n",
        "\n",
        "data = dataset.shuffle(Buffer_Size).batch(Batch_Size, drop_remainder = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rB2jzRt6dA_p",
        "outputId": "35bb61c9-6e12-4116-b5ce-4098810bf650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172\n"
          ]
        }
      ],
      "source": [
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HHi21nq3dCuN"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape = [batch_size, None]),\n",
        "      tf.keras.layers.LSTM(rnn_units,\n",
        "                           return_sequences = True,\n",
        "                           stateful = True,\n",
        "                           recurrent_initializer='glorot_uniform'),\n",
        "      tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MRUEWHgXe3D8",
        "outputId": "a05e2a46-3a76-4f0d-80ac-d013824c4c68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (64, None, 256)           16640     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (64, None, 65)            66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = build_model(Vocab_Size, Embedding_Dim, RNN_Units, Batch_Size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8YZh6eZQfIHW",
        "outputId": "e049951d-fda9-49de-e176-7da4c44419ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64\n",
            "64\n",
            "(64, 100, 65)\n",
            "tf.Tensor(\n",
            "[[[ 3.17284465e-03  1.30099093e-03 -3.44438478e-03 ...  7.72366021e-03\n",
            "   -1.47688086e-04  3.00669088e-03]\n",
            "  [ 6.65297965e-03  6.53506722e-03 -4.82277857e-04 ...  3.42233689e-03\n",
            "    2.62461370e-03  5.84033597e-03]\n",
            "  [ 7.06211897e-03  8.19018763e-03  7.04456354e-04 ...  5.59834344e-03\n",
            "   -5.26425336e-03  4.52357670e-03]\n",
            "  ...\n",
            "  [ 3.77902994e-04  1.29335616e-02 -2.55867746e-03 ...  9.95040312e-03\n",
            "    1.63778197e-04  3.78046092e-03]\n",
            "  [-5.03878761e-03  8.33173376e-03 -2.54076091e-03 ...  5.96209802e-03\n",
            "    4.98775672e-03 -2.94272113e-03]\n",
            "  [-7.12792296e-03  4.65330994e-03  6.43714191e-03 ...  9.83332843e-03\n",
            "    6.10634638e-03 -1.27292378e-03]]\n",
            "\n",
            " [[ 3.17284465e-03  1.30099093e-03 -3.44438478e-03 ...  7.72366021e-03\n",
            "   -1.47688086e-04  3.00669088e-03]\n",
            "  [ 4.85014729e-03  5.25787240e-03 -1.51410431e-03 ...  8.95122439e-03\n",
            "   -7.47495843e-03  3.02486680e-03]\n",
            "  [ 2.55734194e-03  9.37867910e-04  1.21709879e-03 ...  6.84218947e-03\n",
            "   -1.49506405e-02  1.44907914e-03]\n",
            "  ...\n",
            "  [ 2.88960687e-03  7.39834690e-03  1.65898306e-03 ...  9.02035180e-03\n",
            "   -1.15352441e-02  8.29945784e-05]\n",
            "  [ 4.54373471e-03  8.38753302e-03  7.89341796e-03 ...  7.89363123e-03\n",
            "   -8.66873097e-03 -8.48138239e-04]\n",
            "  [ 3.21603147e-03  5.87480655e-03  1.16881961e-02 ...  6.48057461e-03\n",
            "   -5.59609011e-03 -5.85738383e-03]]\n",
            "\n",
            " [[ 3.17284465e-03  1.30099093e-03 -3.44438478e-03 ...  7.72366021e-03\n",
            "   -1.47688086e-04  3.00669088e-03]\n",
            "  [-2.95350025e-03  8.47425777e-04 -3.36674973e-03 ...  3.67926969e-03\n",
            "    4.49399371e-03 -3.55400192e-03]\n",
            "  [-1.83903740e-03  6.94689061e-03 -3.39930598e-03 ...  2.14275089e-03\n",
            "    1.90608285e-03 -6.10122224e-05]\n",
            "  ...\n",
            "  [-1.14701455e-04  7.62338191e-03  1.56120230e-02 ...  8.89452547e-03\n",
            "    8.93521821e-04 -7.09051080e-03]\n",
            "  [ 3.94313270e-03  1.14694554e-02  1.33848963e-02 ...  5.56475064e-03\n",
            "    2.79862247e-03 -3.58297722e-03]\n",
            "  [ 4.83957352e-03  1.23894252e-02  1.05818957e-02 ...  8.40685144e-03\n",
            "   -5.68526797e-03 -3.69455549e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-4.99225920e-03 -1.46587018e-03 -9.93430614e-04 ... -1.78555679e-03\n",
            "    4.39325022e-03 -6.50096592e-03]\n",
            "  [-8.46569746e-05  1.09812559e-03 -4.25879797e-03 ...  7.67265819e-03\n",
            "    3.08193825e-03 -2.37313379e-03]\n",
            "  [ 5.71867172e-03  4.46099695e-03 -5.36995474e-03 ...  6.72218576e-03\n",
            "    6.34248788e-03 -3.54135409e-04]\n",
            "  ...\n",
            "  [ 1.28095073e-03  5.07261185e-03  2.56865798e-03 ...  6.63570827e-03\n",
            "   -1.46971759e-03 -6.76780939e-03]\n",
            "  [ 2.80057965e-03  7.24626100e-03  7.16794981e-03 ...  6.19917968e-03\n",
            "   -1.25055574e-03 -7.62904808e-03]\n",
            "  [-4.10919730e-03  5.00476826e-03  3.92902317e-03 ...  4.57589515e-03\n",
            "    4.92577115e-03 -1.28201898e-02]]\n",
            "\n",
            " [[-2.85008689e-03  1.67050899e-03  2.37110839e-03 ...  1.97234284e-03\n",
            "   -4.41121357e-03 -4.24702186e-04]\n",
            "  [-6.85660867e-03 -1.24324637e-03  1.12983573e-03 ... -2.62584654e-05\n",
            "    1.71678350e-03 -6.89018657e-03]\n",
            "  [ 6.31624134e-05  3.40745412e-03  3.05347191e-03 ... -7.59685878e-04\n",
            "    4.26995894e-03 -2.70161428e-03]\n",
            "  ...\n",
            "  [-1.77110569e-03  6.34702574e-03  4.55779373e-04 ...  3.84157291e-03\n",
            "    2.30998406e-03 -5.05871326e-03]\n",
            "  [ 2.87975185e-03  9.97082610e-03  2.55420478e-03 ...  2.05134647e-03\n",
            "    4.61527845e-03 -8.56180442e-04]\n",
            "  [ 7.20097451e-03  9.41441767e-03 -3.62483086e-04 ...  2.86687305e-03\n",
            "    7.75208045e-03  1.03270868e-04]]\n",
            "\n",
            " [[ 3.38338735e-03  2.30407482e-03  6.42941566e-03 ...  6.16609992e-04\n",
            "   -8.57336679e-04 -1.62833428e-03]\n",
            "  [-2.36035092e-04  3.61052225e-03  7.57281762e-03 ...  3.56557593e-03\n",
            "   -4.54519270e-03 -1.77969690e-03]\n",
            "  [-4.71250480e-03  4.23381367e-04  5.43113844e-03 ...  1.99877843e-03\n",
            "    2.04312848e-03 -7.97474198e-03]\n",
            "  ...\n",
            "  [ 3.77679989e-03  1.08501446e-02  4.34220536e-04 ...  8.78925342e-03\n",
            "   -2.62015359e-03  3.16296727e-03]\n",
            "  [ 4.81340662e-03  1.02926586e-02  7.31010735e-03 ...  6.68206066e-03\n",
            "   -2.19394406e-03  1.28946872e-03]\n",
            "  [ 5.39142359e-03  1.08258715e-02  6.92526624e-03 ...  9.47698392e-03\n",
            "   -8.06164928e-03  1.50856399e-03]]], shape=(64, 100, 65), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_prediction = model(input_example_batch)\n",
        "  print(len(input_example_batch))\n",
        "  print(len(example_batch_prediction))\n",
        "  print(example_batch_prediction.shape)\n",
        "  print(example_batch_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3YHH25ZJjvRu",
        "outputId": "1107c1a9-ae9d-4e0d-edfd-d08880294282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "(100, 65)\n",
            "tf.Tensor(\n",
            "[[ 0.00317284  0.00130099 -0.00344438 ...  0.00772366 -0.00014769\n",
            "   0.00300669]\n",
            " [ 0.00665298  0.00653507 -0.00048228 ...  0.00342234  0.00262461\n",
            "   0.00584034]\n",
            " [ 0.00706212  0.00819019  0.00070446 ...  0.00559834 -0.00526425\n",
            "   0.00452358]\n",
            " ...\n",
            " [ 0.0003779   0.01293356 -0.00255868 ...  0.0099504   0.00016378\n",
            "   0.00378046]\n",
            " [-0.00503879  0.00833173 -0.00254076 ...  0.0059621   0.00498776\n",
            "  -0.00294272]\n",
            " [-0.00712792  0.00465331  0.00643714 ...  0.00983333  0.00610635\n",
            "  -0.00127292]], shape=(100, 65), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "pred = example_batch_prediction[0]\n",
        "print(len(pred))\n",
        "print(pred.shape)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0Uwdaw3Dl4zv",
        "outputId": "73adc73d-6e7c-4d14-d3ae-652356249108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65\n",
            "(65,)\n",
            "tf.Tensor(\n",
            "[ 0.00317284  0.00130099 -0.00344438  0.0043648   0.00709975 -0.0011986\n",
            "  0.00277791 -0.00276993  0.00071152 -0.00360421 -0.00373357 -0.00434108\n",
            " -0.00166894 -0.00143896  0.00264979 -0.00168237 -0.00086114 -0.00024076\n",
            " -0.00452772  0.00051395  0.00105031  0.00014852  0.00498376  0.00487435\n",
            " -0.00283953 -0.0017005   0.00079449  0.00190257 -0.00142065 -0.00274788\n",
            " -0.00167717 -0.0022655   0.00105819  0.00416457 -0.00045712 -0.0017488\n",
            "  0.00330564 -0.0004128   0.00074943  0.00242985  0.0015478   0.0025154\n",
            "  0.00577567  0.00192281  0.00478817 -0.00079689 -0.00156775  0.00093844\n",
            " -0.0049705  -0.00145226 -0.00279273 -0.00311282 -0.00521598 -0.00311043\n",
            " -0.00046661  0.00399549 -0.00672114  0.00099394  0.00416102  0.00736183\n",
            "  0.00360698  0.00472827  0.00772366 -0.00014769  0.00300669], shape=(65,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "time_pred = pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred.shape)\n",
        "print(time_pred)\n",
        "\n",
        "#Remember: 65 is probability of one single character occuring next as in 1/65 characters will occur next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dr5-q6qQmcFc",
        "outputId": "01d36b10-4293-40f8-f88a-272de21c290b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"NRvb,HDt$?Riu\\nJ$Gwry-sJ,?kiL'TKYytOsIzTuY&Fnxg bkHi3nW.F$VZjgw&\\nDs?wphvdCJZmWsXDjbD.VBqdfRJLjk;PVxDZ\""
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)\n",
        "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
        "\n",
        "# now we can reshape that array and convert all the integers to numbers to see the actual characters\n",
        "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
        "predicted_chars = int_to_text(sampled_indices)\n",
        "\n",
        "print(len(predicted_chars))\n",
        "predicted_chars  # and this is what the model predicted for training sequence 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3K4cvgTWnPgb"
      },
      "outputs": [],
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cl5fLNCw_3F4"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xB6jDNCCAAU-"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt{epoch}')\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath= checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Opb2wtHA6Zv",
        "outputId": "f0131f14-0719-4152-f0d4-3df296ebea08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "172/172 [==============================] - 17s 82ms/step - loss: 2.5988\n",
            "Epoch 2/70\n",
            "172/172 [==============================] - 13s 74ms/step - loss: 1.9210\n",
            "Epoch 3/70\n",
            "172/172 [==============================] - 12s 72ms/step - loss: 1.6755\n",
            "Epoch 4/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 1.5317\n",
            "Epoch 5/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 1.4441\n",
            "Epoch 6/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 1.3833\n",
            "Epoch 7/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 1.3366\n",
            "Epoch 8/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 1.2965\n",
            "Epoch 9/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 1.2608\n",
            "Epoch 10/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 1.2263\n",
            "Epoch 11/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 1.1923\n",
            "Epoch 12/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 1.1574\n",
            "Epoch 13/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 1.1216\n",
            "Epoch 14/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 1.0864\n",
            "Epoch 15/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 1.0479\n",
            "Epoch 16/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 1.0093\n",
            "Epoch 17/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.9722\n",
            "Epoch 18/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.9335\n",
            "Epoch 19/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.8955\n",
            "Epoch 20/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.8602\n",
            "Epoch 21/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.8243\n",
            "Epoch 22/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 0.7929\n",
            "Epoch 23/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 0.7628\n",
            "Epoch 24/70\n",
            "172/172 [==============================] - 13s 73ms/step - loss: 0.7353\n",
            "Epoch 25/70\n",
            "172/172 [==============================] - 13s 73ms/step - loss: 0.7095\n",
            "Epoch 26/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.6856\n",
            "Epoch 27/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 0.6654\n",
            "Epoch 28/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.6449\n",
            "Epoch 29/70\n",
            "172/172 [==============================] - 13s 73ms/step - loss: 0.6269\n",
            "Epoch 30/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 0.6116\n",
            "Epoch 31/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.5967\n",
            "Epoch 32/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.5818\n",
            "Epoch 33/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 0.5708\n",
            "Epoch 34/70\n",
            "172/172 [==============================] - 13s 71ms/step - loss: 0.5577\n",
            "Epoch 35/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.5466\n",
            "Epoch 36/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 0.5394\n",
            "Epoch 37/70\n",
            "172/172 [==============================] - 13s 73ms/step - loss: 0.5285\n",
            "Epoch 38/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.5203\n",
            "Epoch 39/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 0.5148\n",
            "Epoch 40/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 0.5071\n",
            "Epoch 41/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 0.5010\n",
            "Epoch 42/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 0.4958\n",
            "Epoch 43/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.4891\n",
            "Epoch 44/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.4836\n",
            "Epoch 45/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 0.4789\n",
            "Epoch 46/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 0.4756\n",
            "Epoch 47/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 0.4719\n",
            "Epoch 48/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 0.4670\n",
            "Epoch 49/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 0.4617\n",
            "Epoch 50/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 0.4601\n",
            "Epoch 51/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 0.4557\n",
            "Epoch 52/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.4532\n",
            "Epoch 53/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.4499\n",
            "Epoch 54/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.4473\n",
            "Epoch 55/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.4457\n",
            "Epoch 56/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 0.4434\n",
            "Epoch 57/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.4410\n",
            "Epoch 58/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 0.4380\n",
            "Epoch 59/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 0.4361\n",
            "Epoch 60/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.4368\n",
            "Epoch 61/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 0.4313\n",
            "Epoch 62/70\n",
            "172/172 [==============================] - 13s 71ms/step - loss: 0.4300\n",
            "Epoch 63/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 0.4308\n",
            "Epoch 64/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 0.4275\n",
            "Epoch 65/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.4253\n",
            "Epoch 66/70\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 0.4245\n",
            "Epoch 67/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.4243\n",
            "Epoch 68/70\n",
            "172/172 [==============================] - 13s 72ms/step - loss: 0.4240\n",
            "Epoch 69/70\n",
            "172/172 [==============================] - 12s 71ms/step - loss: 0.4211\n",
            "Epoch 70/70\n",
            "172/172 [==============================] - 12s 72ms/step - loss: 0.4183\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(data, epochs=70, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZM3UdmWhBEvu"
      },
      "outputs": [],
      "source": [
        "model = build_model(Vocab_Size, Embedding_Dim, RNN_Units, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aQLmXAi3BbQE"
      },
      "outputs": [],
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MchfNJUYB6gM"
      },
      "outputs": [],
      "source": [
        "#checkpoint_num = 4\n",
        "#model.load_weights(tf.train.load.checkpoint(\"\"./training_checkpoints/ckpt_\" + str(checkpoint_num)\"\"))\n",
        "#model.build(tf.TensorShape([1, None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G5utCWMFCXrd"
      },
      "outputs": [],
      "source": [
        "def Generate_text(model, start_string):\n",
        "  num_generate = 800\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        "  temprature = 1.2\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "    predictions = predictions / temprature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples = 1)[-1,0].numpy()\n",
        "\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgm02QKNDtYE"
      },
      "outputs": [],
      "source": [
        "inp = input(\"Type a starting string: \")\n",
        "print(Generate_text(model, inp))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ4euyIGkJ53uJR6rZVs62",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}